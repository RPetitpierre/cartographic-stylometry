{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/remipetitpierre/opt/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import cv2, glob, tqdm, os, imutils, json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "from skimage.morphology import skeletonize\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from geneticalgorithm import geneticalgorithm as ga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unroll(list_):\n",
    "    return [i for item in list_ for i in item]\n",
    "\n",
    "def cutMapels(image, patch_size: int = 50):\n",
    "    ''' Cut images into mapels '''\n",
    "    \n",
    "    if len(image.shape) > 2:\n",
    "        dimension = image.shape[2]\n",
    "    else:\n",
    "        dimension = 1\n",
    "        \n",
    "    img = image.copy()\n",
    "    shape = img.shape[:2]\n",
    "    \n",
    "    # Crop if not divisible by patch size\n",
    "    if shape[0]%patch_size > 0:\n",
    "        img = img[:-(shape[0]%patch_size)]\n",
    "    if shape[1]%patch_size > 0:\n",
    "        img = img[:, :-(shape[1]%patch_size)]\n",
    "        \n",
    "    return img.reshape((shape[0]//patch_size, patch_size, shape[1]//patch_size, patch_size, dimension))\n",
    "\n",
    "def computeGraphicalLoad(patch):\n",
    "    ''' Edge-detection-based graphical load '''\n",
    "\n",
    "    graphical_load, scharr = [], []\n",
    "    for i in range(3):\n",
    "        scharr.append((cv2.Scharr(patch, -1, 0, 1)*0.5).astype('uint8') + (cv2.Scharr(\n",
    "                            patch, -1, 1, 0)*0.5).astype('uint8'))\n",
    "        graphical_load.append(np.mean(scharr[-1]))\n",
    "        patch = cv2.resize(patch, (patch.shape[1]//2, patch.shape[0]//2))\n",
    "    graphical_load = np.sqrt(np.mean(graphical_load))\n",
    "    \n",
    "    return graphical_load, scharr[0]\n",
    "\n",
    "def normalizeOrientation(image, mapel_center):\n",
    "    ''' Normalize mapel orientation'''\n",
    "\n",
    "    x, y = mapel_center\n",
    "\n",
    "    patch = image[x-25:x+25, y-25:y+25]\n",
    "\n",
    "    gray = cv2.blur(cv2.cvtColor(patch, cv2.COLOR_BGR2GRAY), (3, 3))\n",
    "    hog_feat = hog(gray, orientations=180, pixels_per_cell=(50, 50), cells_per_block=(1, 1),\n",
    "                   feature_vector=False)[0,0,0,0]\n",
    "    \n",
    "    hog_feat[0] = hog_feat[90] = 0\n",
    "    angle = np.argmax(hog_feat)\n",
    "\n",
    "    mapel = imutils.rotate(image[x-36:x+36, y-36:y+36], angle)[11:-11, 11:-11]\n",
    "    \n",
    "    return mapel, angle\n",
    "\n",
    "def getHOG(patch, px_per_cell: int = 5):\n",
    "    ''' Compute the Histogram of Oriented Gradient (HOG) morphological descriptor '''\n",
    "    \n",
    "    hog_feat = hog(patch, orientations=12, pixels_per_cell=(px_per_cell, px_per_cell), cells_per_block=(1, 1),\n",
    "                   feature_vector=False)[:,:,0,0]\n",
    "    \n",
    "    hog_feat = np.sum(np.sum(hog_feat, axis=0), axis=0)\n",
    "    \n",
    "    return hog_feat\n",
    "\n",
    "def getHOG_orient(patch):\n",
    "    ''' Compute HOG compact orientations '''\n",
    "    \n",
    "    hog = getHOG(patch)\n",
    "    hog = np.concatenate((np.asarray([hog[:,0]]).T, np.asarray([hog[:,12]]).T, \n",
    "                    np.asarray([hog[:,6]+hog[:,18]]).T, \n",
    "                    np.asarray([hog[:,4]+hog[:,8]+hog[:,16]+hog[:,22]]).T, np.asarray(\n",
    "        [hog[:,1]+hog[:,2]+hog[:,3]+hog[:,5]+hog[:,7]+hog[:,9]+hog[:,10]+hog[:,11]+hog[:,13]+\\\n",
    "         hog[:,14]+hog[:,15]+hog[:,17]+hog[:,19]+hog[:,21]+hog[:,22]+hog[:,23]]).T), axis=1)\n",
    "    \n",
    "    return hog\n",
    "\n",
    "def getComponentsFeatures(patch):\n",
    "    ''' Compute topological features '''\n",
    "\n",
    "    black_pix_n = np.sum(patch == 0)\n",
    "    skeleton = skeletonize(1-patch.astype('bool'))\n",
    "    black_skel_n = np.sum(skeleton == 1)\n",
    "    pix_ratio = black_skel_n/black_pix_n\n",
    "    _, cc_map = cv2.connectedComponents(skeleton.astype('uint8'))\n",
    "    _, cc_cnt = np.unique(cc_map, return_counts=True)\n",
    "    n_cc = np.sum(cc_cnt > 10)\n",
    "    \n",
    "    return pix_ratio, n_cc\n",
    "\n",
    "def getLBPdescriptors(image: np.ndarray, lbp_radius:int = 2, histogram_bins: int = 12):\n",
    "    ''' Compute Linear Binary Patterns (LBP) texture descriptors'''\n",
    "    \n",
    "    lbp = (local_binary_pattern(image, 8*lbp_radius, lbp_radius, 'uniform')).astype('uint8')\n",
    "    \n",
    "    return np.histogram(lbp, bins=12, range=(0, 17))[0]\n",
    "\n",
    "def getColorDescriptors(image: np.ndarray, patch_size:int = 50, histogram_bins: int = 255):\n",
    "    ''' Compute color moments '''\n",
    "    \n",
    "    assert (len(image.shape) == 3), \"The image should have 3 color channels\"\n",
    "    \n",
    "    b, g, r = cv2.split(image)\n",
    "\n",
    "    color_feat = []\n",
    "    for color in [b, g, r]:\n",
    "        features = []\n",
    "        for i in range((image.shape[0]//patch_size)):\n",
    "            for j in range((image.shape[1]//patch_size)):\n",
    "                patch = color[i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size]\n",
    "                features.append(np.histogram(patch, bins=histogram_bins, range=(0, 255))[0])\n",
    "        features = np.asarray(features)\n",
    "        mean = np.argmax(features, axis=1)\n",
    "        std = np.std(features, axis=1)\n",
    "        skewness = skew(features, axis=1)\n",
    "        kurt = kurtosis(features, axis=1)\n",
    "        color_feat.append(np.array([mean, std, skewness, kurt]))\n",
    "        \n",
    "    color_feat = np.concatenate(color_feat).T\n",
    "    \n",
    "    return color_feat\n",
    "\n",
    "def getColorHist(patch: np.ndarray, histogram_bins: int = 12):\n",
    "    ''' Compute color histogram '''\n",
    "    \n",
    "    assert (len(patch.shape) == 3), \"The image should have 3 color channels\"\n",
    "    \n",
    "    b, g, r = cv2.split(patch)\n",
    "\n",
    "    color_feat = []\n",
    "    for color in [b, g, r]:\n",
    "        color_feat.append(np.histogram(color, bins=histogram_bins, range=(0, 255))[0]/(patch.shape[\n",
    "            0]*patch.shape[1]))\n",
    "        \n",
    "    color_feat = np.concatenate(color_feat).T\n",
    "    \n",
    "    return color_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus:\n",
    "    \n",
    "    def __init__(self, subset, paths):\n",
    "        \n",
    "        self.df = subset\n",
    "        self.arks = subset['ark'].values\n",
    "        self.scale = [subset['est_scale'].min(), subset['est_scale'].max()]\n",
    "        self.timespan = [subset['est_date'].apply(np.min).min(), subset['est_date'].apply(np.max).max()]\n",
    "        \n",
    "        mask = np.array([(path.split('/')[-1].split('-')[0] in self.arks) for path in paths])\n",
    "        self.img_paths = np.array(paths)[mask]\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code\n",
    "## Select Corpus\n",
    "Load the corpus of images and select the subcorpora corresponding to the training sample for the optimization of the feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10548"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = glob.glob('images/*.tif')\n",
    "len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1063"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('metadata.json')\n",
    "df_paris = df[(df['title_LOC'] == 'Paris')]\n",
    "\n",
    "melotte = Corpus(df[df['creator'] == 'Melotte'], paths)\n",
    "berney = Corpus(df[df['creator'] == 'Abram Berney'], paths)\n",
    "deluz = Corpus(df[df['creator'] == 'Louis Deluz'], paths)\n",
    "\n",
    "jacoubet = Corpus(df_paris[np.array(['jacoubet' in row.keywords[\n",
    "    'PER'] for row in df_paris.itertuples()])], paths)\n",
    "alphand = Corpus(df_paris[np.array(['alphand' in row.keywords[\n",
    "    'PER'] for row in df_paris.itertuples()])], paths)\n",
    "\n",
    "ad_rhone = Corpus(df[(df['institution'] == 'AD Rhone') & (df['est_scale'] < 10000)], paths)\n",
    "ad_carmor = Corpus(df[(df['institution'] == 'AD Cotes Armor') & (df['est_scale'] == 2000)], paths)\n",
    "ad_hmarne = Corpus(df[(df['institution'] == 'AD Haute Marne') & (df['est_scale'] <= 1500)], paths)\n",
    "\n",
    "etat_major_40k = Corpus(df[(df['publisher'] == 'Etat Major') & (df['est_scale'] == 40000)], paths)\n",
    "etat_major_50k = Corpus(df[(df['publisher'] == 'Etat Major') & (df['est_scale'] == 50000)], paths)\n",
    "swisstopo = Corpus(df[df['institution'] == 'SwissTopo'], paths)\n",
    "\n",
    "datasets = {'melotte': melotte, 'berney': berney, 'deluz': deluz, 'jacoubet': jacoubet, 'alphand': alphand, \n",
    "            'ad_rhone': ad_rhone, 'ad_carmor': ad_carmor, 'ad_hmarne': ad_hmarne, \n",
    "            'etat_major_40k': etat_major_40k, 'etat_major_50k': etat_major_50k, 'swisstopo': swisstopo}\n",
    "\n",
    "# Compute and display the length of the training sample\n",
    "datasets_len = []\n",
    "for ds in datasets.values():\n",
    "    datasets_len.append(len(ds))\n",
    "np.sum([len(ds) for ds in datasets.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_paths = []\n",
    "for ds in datasets.values():\n",
    "    datasets_paths += [path.split('/')[-1][:-4] for path in ds.img_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample mapels and compute figurative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10548 [00:00<?, ?it/s]<ipython-input-42-402b1d6583f5>:26: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  gload = np.array([computeGraphicalLoad(patch) for patch in img_patches])\n",
      "<ipython-input-42-402b1d6583f5>:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  texels, ORIENTATION = np.array([normalizeOrientation(image, center) for center in texel_centers]).T\n",
      "100%|██████████| 10548/10548 [40:48:01<00:00, 13.93s/it]    \n"
     ]
    }
   ],
   "source": [
    "patch_size = 50\n",
    "half_size = patch_size//2\n",
    "\n",
    "patch_indices = np.indices((patch_size, patch_size))\n",
    "patch_indices = np.reshape(patch_indices, (2, patch_size*patch_size)).T\n",
    "\n",
    "# Iterate over the image paths\n",
    "for path in tqdm.tqdm(paths):\n",
    "    \n",
    "    # Load image\n",
    "    image = cv2.imread(path)\n",
    "    img_name = path.split('/')[-1][:-4]\n",
    "    \n",
    "    # Get patches indices\n",
    "    indices = np.indices((image.shape[0]//patch_size, image.shape[1]//patch_size))*50\n",
    "    indices = np.array(unroll(np.swapaxes(indices.T, 0, 1)))\n",
    "    image_border = np.max(indices, axis=0)\n",
    "    \n",
    "    # Border mask, corresponding to the map background\n",
    "    border_mask = (indices[:,0] < image_border[0]) & (indices[:,1] < image_border[1]) & (\n",
    "        indices[:,0] > 0) & (indices[:,1] > 0)\n",
    "        \n",
    "    # Cut candidate patches in the whole image\n",
    "    img_patches = np.concatenate(np.swapaxes(cutMapels(image, patch_size), 1, 2), axis=0)[border_mask]\n",
    "    \n",
    "    # Exclude patches overlapping with the map background\n",
    "    black_mask = (np.sum(np.sum(np.sum(img_patches, 3) == 0, 2), 1) < 50)\n",
    "    img_patches, indices = img_patches[black_mask], indices[border_mask][black_mask]\n",
    "    \n",
    "    # Compute graphical load\n",
    "    gload = np.array([computeGraphicalLoad(patch) for patch in img_patches])\n",
    "    GL_LOAD_AREA = np.sum(gload[:,0] >= 4.4)/len(gload)\n",
    "    GL_HIST = np.histogram(gload[:,0], range=(0, 12), bins=12)[0]/len(gload)\n",
    "    \n",
    "    # Center patch on the most salient graphical element (darkest pixel)\n",
    "    mapel_centers = np.array([(patch_indices[np.argmax(scharr)]+ind).tolist() for ind, scharr in zip(indices,\n",
    "                               np.sum(np.array(gload[:, 1].tolist()), axis=3))])\n",
    "    mapels = np.array([image[center[0]-half_size:center[0]+half_size,\n",
    "                             center[1]-half_size:center[1]+half_size] for center in mapel_centers])\n",
    "    \n",
    "    # Remove background patches again\n",
    "    black_mask = (np.sum(np.sum(np.sum(mapels, 3) == 0, 2), 1) < 50)\n",
    "    mapels, mapel_centers = mapels[black_mask], mapel_centers[black_mask]\n",
    "        \n",
    "    # Apply graphical load criterium\n",
    "    gl_feat = np.array([computeGraphicalLoad(mapel)[0] for mapel in mapels])\n",
    "    gl_mask = (gl_feat >= 4.4)\n",
    "    mapels, mapel_centers, gl_feat = mapels[gl_mask], mapel_centers[gl_mask], gl_feat[gl_mask]\n",
    "    \n",
    "    # Sample the remaining candidate patches (without replacement whenever possible)\n",
    "    \n",
    "    sample_ind = np.arange(len(mapel_centers))\n",
    "    if len(mapel_centers) >= 800:\n",
    "        sample = resample(sample_ind, replace=False, n_samples=800)\n",
    "    else:\n",
    "        sample = resample(sample_ind, replace=True, n_samples=800)\n",
    "    \n",
    "    # Normalize the orientation of the mapels\n",
    "    mapels, mapel_centers = mapels[sample], mapel_centers[sample]\n",
    "    mapels, ORIENTATION = np.array([normalizeOrientation(image, center) for center in mapel_centers]).T\n",
    "    \n",
    "    gray_mapels = [cv2.cvtColor(mapel, cv2.COLOR_RGB2GRAY) for mapel in mapels]\n",
    "    bin_mapels = [cv2.threshold(mapel.copy(), 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU\n",
    "                               )[1] for mapel in gray_mapels]\n",
    "    \n",
    "    GL_AFTER_REORIENT = np.array([computeGraphicalLoad(mapel)[0] for mapel in mapels])\n",
    "    \n",
    "    LBP_2 = np.array([getLBPdescriptors(mapel, lbp_radius=2)[0] for mapel in mapels])\n",
    "    LBP_3 = np.array([getLBPdescriptors(mapel, lbp_radius=3)[0] for mapel in mapels])\n",
    "    LBP_4 = np.array([getLBPdescriptors(mapel, lbp_radius=4)[0] for mapel in mapels])\n",
    "    \n",
    "    COLOR_DESC = np.array([getColorDescriptors(mapel)[0] for mapel in mapels])\n",
    "    COLOR_HIST_6 = np.array([getColorHist(mapel, 6) for mapel in mapels])\n",
    "    COLOR_HIST_9 = np.array([getColorHist(mapel, 9) for mapel in mapels])\n",
    "    \n",
    "    HOG_BIN_ORIENT = np.array([getHOG_orient(mapel) for mapel in mapels])[:,0]\n",
    "    HOG_5 = np.array([getHOG(mapel, 5) for mapel in mapels])\n",
    "    HOG_10 = np.array([getHOG(mapel, 10) for mapel in mapels])\n",
    "    HOG_25 = np.array([getHOG(mapel, 25) for mapel in mapels])\n",
    "    \n",
    "    COMP = np.array([getComponentsFeatures(mapel) for mapel in bin_mapels])\n",
    "    \n",
    "    features = np.concatenate([ORIENTATION.reshape(-1,1),\n",
    "                               HOG_BIN_ORIENT,\n",
    "                               GL_AFTER_REORIENT.reshape(-1,1),\n",
    "                               LBP_2, LBP_3, LBP_4,\n",
    "                               COLOR_DESC, COLOR_HIST_6, COLOR_HIST_9,\n",
    "                               HOG_5, HOG_10, HOG_25,\n",
    "                               COMP], axis=1)\n",
    "        \n",
    "    # Save patches\n",
    "    cv2.imwrite(f'mapels/{img_name}.tif', np.concatenate(mapels, axis=0))\n",
    "    \n",
    "    # Save mapels features\n",
    "    np.save(f'features/{img_name}.npy', features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize feature weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "\n",
    "best_score = -100.\n",
    "\n",
    "def f(X):\n",
    "    \n",
    "    ''' Objective function '''\n",
    "    \n",
    "    global best_score\n",
    "    \n",
    "    # Features description\n",
    "    feat_structure = {\n",
    "        'ORIENTATION': {'norm': np.array([179.])/X[0], 'active': True},\n",
    "        'HOG_BIN_ORIENT': {'norm': [72., 72., 72., 72., 72.*4], 'active': False},\n",
    "        'GL_AFTER': {'norm': np.array([12.])/X[1], 'active': True},\n",
    "        'LBP_2': {'norm': np.array(12*[1.]), 'active': False},\n",
    "        'LBP_3': {'norm': np.array(12*[1.]), 'active': False},\n",
    "        'LBP_4': {'norm': np.array(12*[1.])/X[2], 'active': True},\n",
    "        'COLOR_DESC': {'norm': np.array(3*[254.*np.inf, 153.*np.inf, 16.*np.inf, 250.*np.inf]), 'active': False},\n",
    "        'COLOR_HIST_6': {'norm': 18*[1.], 'active': False},\n",
    "        'COLOR_HIST_9': {'norm': 27*[1.], 'active': False},\n",
    "        'HOG_5': {'norm': 12*[484/100], 'active': False},\n",
    "        'HOG_10': {'norm': np.array(12*[484/25]), 'active': False},\n",
    "        'HOG_25': {'norm': np.array(12*[484/4])/X[3], 'active': True},\n",
    "        'NOTSU': {'norm': [2500.], 'active': False},\n",
    "        'SKEL_RATIO': {'norm': np.array([1.])/X[4], 'active': True},\n",
    "        'NCOMP': {'norm': np.array([21.])/X[5], 'active': True},\n",
    "    }\n",
    "\n",
    "    # Create normalization vector and features mask\n",
    "    normalization = np.array(unroll([feat_structure[key]['norm'] if feat_structure[key][\n",
    "        'active'] else [] for key in feat_structure.keys()]))\n",
    "\n",
    "    mask = np.array(unroll([len(feat_structure[key]['norm'])*[True] if feat_structure[key][\n",
    "        'active'] else len(feat_structure[key]['norm'])*[False] for key in feat_structure.keys()]))\n",
    "\n",
    "    # Subset paths corresponding to the training subset\n",
    "    with open('subset_paths.json', 'r') as f:\n",
    "        subset_paths = json.load(f)\n",
    "\n",
    "    # Load image features\n",
    "    image_features = torch.Tensor([(np.load(f'features/{img_name}.npy', allow_pickle=True)[:, mask]\n",
    "                                   )/normalization for img_name in subset_paths]).to(device)\n",
    "    n = image_features.shape[0]\n",
    "    \n",
    "    # Compute distance matrices (Equation 2)\n",
    "    K = np.arange(0.0, 0.1, 0.001)\n",
    "    matrix = []\n",
    "    for i in range(n):\n",
    "        dist_matrix = torch.cdist(image_features[i], image_features)\n",
    "        dist_0 = dist_matrix.min(dim=1).values\n",
    "        matrix.append(torch.cat([(dist_0 <= k).sum(dim=1) for k in K]).view(len(K), -1).T.true_divide(800))\n",
    "    matrix = torch.cat(matrix).view(n, n, len(K)).cpu()\n",
    "\n",
    "    # Classes encoding\n",
    "    datasets_len = [10, 10, 21, 56, 48, 116, 289, 329, 20, 22, 142]\n",
    "    classes = []\n",
    "    for i, N in enumerate(datasets_len):\n",
    "        classes += N*[i]\n",
    "    classes = np.array(classes)\n",
    "\n",
    "    largest_dist = -1\n",
    "    best_params = ()\n",
    "    best_matrix = None\n",
    "    \n",
    "    # Compute optimal value of k, the radius of free variation, for this features set\n",
    "    for k in range(len(K)):\n",
    "        matrix_ = torch.cat([matrix[:,:,k], matrix[:,:,k].T]).view(2, n, n).mean(0).numpy()\n",
    "        np.fill_diagonal(matrix_, np.nan)\n",
    "\n",
    "        interclass, interclass_std = [], []\n",
    "        class_matrix, class_matrix_std = np.zeros((11, 11)), np.zeros((11, 11))\n",
    "        for i in range(11):\n",
    "            for j in range(11):\n",
    "                class_matrix[i, j] = np.nanmedian(matrix_[classes == i][:,classes == j])\n",
    "                class_matrix_std[i, j] = np.nanstd(matrix_[classes == i][:,classes == j])\n",
    "                if i != j:\n",
    "                    interclass.append(class_matrix[i, j])\n",
    "                    interclass_std.append(class_matrix_std[i, j])\n",
    "\n",
    "        intraclass = np.diag(class_matrix)-np.diag(class_matrix_std)\n",
    "\n",
    "        # Equation 3\n",
    "        stat_dist = np.abs(np.mean(np.diag(class_matrix)) - np.mean(interclass))/(\n",
    "            0.5*np.mean(np.diag(class_matrix_std)) + 0.5*np.mean(interclass_std))\n",
    "\n",
    "        # Save the best solution to Eq. 3 given the different values of k\n",
    "        if stat_dist > largest_dist:\n",
    "            largest_dist = stat_dist\n",
    "            best_params = (l, K[k])\n",
    "            best_matrix = matrix_.copy()\n",
    "                \n",
    "    # Save the best solution\n",
    "    if largest_dist > best_score:\n",
    "        best_score = largest_dist\n",
    "        image = Image.fromarray((best_matrix*255).astype('uint8'))\n",
    "        image.save(f'optim/best_matrix.png', 'PNG')\n",
    "        with open('optim/best_matrix.npy', 'wb') as f:\n",
    "            np.save(f, best_matrix)\n",
    "\n",
    "    return 10 - largest_dist\n",
    "\n",
    "\n",
    "# Research space for the weights\n",
    "boundaries = np.array([6*[0.01, 1.0]]).reshape(6, 2)\n",
    "\n",
    "# Parameters of the genetic algorithm\n",
    "algorithm_param = {'max_num_iteration': 80,\n",
    "                   'population_size': 20,\n",
    "                   'mutation_probability': 0.2,\n",
    "                   'elit_ratio': 0.1,\n",
    "                   'crossover_probability': 0.5,\n",
    "                   'parents_portion': 0.2,\n",
    "                   'crossover_type': 'uniform',\n",
    "                   'max_iteration_without_improv': 20}\n",
    "\n",
    "# Genetic algorithm\n",
    "model = ga(function=f, dimension=6, variable_type='real', variable_boundaries=boundaries,\n",
    "           algorithm_parameters=algorithm_param, convergence_curve=False)\n",
    "model.run()\n",
    "\n",
    "# Best solution\n",
    "X = np.array([0.05, 0.15, 0.1, 1.0, 0.25, 0.25])\n",
    "f(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
