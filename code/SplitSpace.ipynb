{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, glob, json\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unroll(list_):\n",
    "    return [i for item in list_ for i in item]\n",
    "    \n",
    "def splitSpace(x: np.ndarray, center = None, n_partitions: int = 4, min_samples: int = 4, ):\n",
    "    \n",
    "    ''' Function that recursively splits the space\n",
    "    \n",
    "    Inputs:\n",
    "        x: the input features [len x dim]\n",
    "        center: the center from the previous iteration\n",
    "        n_partitions: the space will be divided into n partitions at each iteration\n",
    "        min_samples: the minimum number of samples in a partition\n",
    "        \n",
    "    Output:\n",
    "        [list]: a (k x m) nested list of cluster centers, with k clusters and m dimensions\n",
    "    '''\n",
    "    if center is None:\n",
    "        center = np.zeros((x.shape[1]))\n",
    "    \n",
    "    if (len(x) >= min_samples):\n",
    "        if (np.sum((x - center)**2, 1).max() > 2.25e-4):\n",
    "            kmeans = KMeans(n_clusters=n_partitions).fit(x)\n",
    "            centers = unroll([splitSpace(x[kmeans.labels_ == i],\n",
    "                              kmeans.cluster_centers_[i], n_partitions) for i in range(n_partitions)])\n",
    "            return centers\n",
    "        else:\n",
    "            return [center]\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code\n",
    "### Normalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_structure = {\n",
    "    'ORIENTATION': {'norm': [179.], 'active': True}, \n",
    "    'GL_AFTER': {'norm': np.array([12.]), 'active': True},\n",
    "    'LBP_4': {'norm': np.array(12*[1.]), 'active': True}, \n",
    "    'HOG_25': {'norm': 12*[484/4], 'active': True},\n",
    "    'SKEL_RATIO': {'norm': [1.], 'active': True},\n",
    "    'NCOMP': {'norm': [21.], 'active': True},\n",
    "}\n",
    "\n",
    "weights = np.array([0.05, 0.15, 0.1, 1.0, 0.25, 0.25])\n",
    "\n",
    "normalization = []\n",
    "for i, key in enumerate(feat_structure.keys()):\n",
    "    normalization.append(feat_structure[key]['norm']/weights[i])\n",
    "normalization = np.array(unroll(normalization))\n",
    "ndim = len(normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load mapels images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = glob.glob('mapels/*.npy')\n",
    "len(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features = torch.Tensor([np.load(path, allow_pickle=True) for path in paths])/normalization\n",
    "n = image_features.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteratively splits the space, compute mapotypes centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = splitSpace(np.unique(image_features.view(-1, ndim).numpy(), axis=0), None, 2)\n",
    "centers = torch.Tensor(centers)\n",
    "centers.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute mapels to mapotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = NearestNeighbors(n_neighbors=1)\n",
    "neigh.fit(centers)\n",
    "\n",
    "cluster_n = np.array([neigh.kneighbors(feat, 1, return_distance=False) for feat in image_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Volumes/Data_archives/Cartes/PhD/visual_analytical/cluster_attribution_2.npy', 'wb') as f:\n",
    "    np.save(f, cluster_n)\n",
    "with open('/Volumes/Data_archives/Cartes/PhD/visual_analytical/cluster_centers_2.npy', 'wb') as f:\n",
    "    np.save(f, centers.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
